---
title: "Simulation 1: Inference of the Unknown Periodicity"
author: "Ziang Zhang"
date: "2025-04-15"
output: 
  workflowr::wflow_html:
    code_folding: show
editor_options:
  chunk_output_type: console
---

## Data

```{r message=FALSE, warning=FALSE}
library(BayesGP)
library(tidyverse)
library(npreg)
function_path <- "./code"
output_path <- "./output/sim1"
data_path <- "./data/sim1"
source(paste0(function_path, "/00_BOSS.R"))
```

We simulate $n = 100$ data with true periodicity $a = 1.5$:
\[
\begin{aligned}
    y_i|\mu_i &\overset{ind}{\sim} \text{Poisson}(\mu_i), \\
    \log(\mu_i) =& 1 + 
    0.5 \cos\bigg(\frac{2\pi x_i}{1.5}\bigg) - 1.3  \sin\bigg(\frac{2\pi x_i}{1.5}\bigg) + \\
    & 1.1 \cos\bigg(\frac{4\pi x_i}{1.5}\bigg) + 0.3  \sin\bigg(\frac{4\pi x_i}{1.5}\bigg) + \epsilon_i, \\
    \epsilon_i &\overset{iid}{\sim} \mathcal{N}(0,4).
\end{aligned}
\]
The covariates $\boldsymbol{x} = \{x_i\}_{i=1}^n$ are independently simulated from $\text{Unif}[0,10]$.

```{r message=FALSE, warning=FALSE}
lower = 0.5; upper = 4.5; a = 1.5; noise_var = 1e-6
### Simulate data:
set.seed(123)
n <- 100
x <- runif(n = n, min = 0, max = 10)
true_func <- function(x, true_alpha = 1.5){1 + 
    0.5 * cos((2*pi*x)/true_alpha) - 1.3 * sin((2*pi*x)/true_alpha) +
    1.1 * cos((4*pi*x)/true_alpha) + 0.3 * sin((4*pi*x)/true_alpha)}
log_mu <- true_func(x) + rnorm(n, sd = 2)
y <- rpois(n = n, lambda = exp(log_mu))
data <- data.frame(y = y, x = x, indx = 1:n, log_mu = log_mu)
plot(y ~ x, type = "p", data = arrange(data, x))
```

Assume the prior is $\alpha \sim N(3, 0.5^2)$, we then define the objective function needed for BOSS:

```{r message=FALSE, warning=FALSE}
log_prior <- function(alpha){
  dnorm(x = alpha, mean = 3, log = T, sd = 0.5)
}
eval_once <- function(alpha){
  a_fit <- (2*pi)/alpha
  x <- data$x
  data$cosx <- cos(a_fit * x)
  data$sinx <- sin(a_fit * x)
  data$cos2x <- cos(2*a_fit * x)
  data$sin2x <- sin(2*a_fit * x)
  mod <- model_fit(formula = y ~ cosx + sinx + cos2x + sin2x + f(x = indx, model = "IID", 
                                                                 sd.prior = list(param = 1)),
                   data = data, method = "aghq", family = "Poisson", aghq_k = 4
  )
  (mod$mod$normalized_posterior$lognormconst) + log_prior(alpha)
}
surrogate <- function(xvalue, data_to_smooth, choice_cov) {
  predict_gp(
    data = data_to_smooth,
    x_pred = matrix(xvalue, ncol = 1),
    choice_cov = choice_cov,
    noise_var = noise_var
  )$mean
}
```



## Exact Grid Implementation

First, as an oracle approach, we set up a dense grid on $[0.5,4.5]$:

```{r message=FALSE, warning=FALSE}
x_vals <- seq(lower, upper, by = 0.005)
```

Compute the objective function on the grid:

```{r eval=FALSE}
begin_time <- Sys.time()
total <- length(x_vals)
pb <- txtProgressBar(min = 0, max = total, style = 3)
exact_vals <- c()
for (i in 1:total) {
  xi <- x_vals[i]
  exact_vals <- c(exact_vals, eval_once(xi))
  setTxtProgressBar(pb, i)
}
close(pb)
exact_grid_result <- data.frame(x = x_vals, exact_vals = exact_vals)
exact_grid_result$exact_vals <- exact_grid_result$exact_vals - max(exact_grid_result$exact_vals)
exact_grid_result$fx <- exp(exact_grid_result$exact_vals)
end_time <- Sys.time()
end_time - begin_time

# Calculate the differences between adjacent x values
dx <- diff(exact_grid_result$x)
# Compute the trapezoidal areas and sum them up
integral_approx <- sum(0.5 * (exact_grid_result$fx[-1] + exact_grid_result$fx[-length(exact_grid_result$fx)]) * dx)
exact_grid_result$pos <- exact_grid_result$fx / integral_approx
plot(exact_grid_result$x, exact_grid_result$pos, type = "l", col = "red", xlab = "x (0-10)", ylab = "density", main = "Posterior")
abline(v = a, col = "purple")
grid()
save(exact_grid_result, file = paste0(output_path, "/exact_grid_result.rda"))
```

We can take a quick look at the posterior density obtained from the exact grid.
Because of the strong prior centered at $\alpha = 3$, the posterior density is not exactly unimodal at the true value $1.5$.

```{r message=FALSE, warning=FALSE}
load(paste0(output_path, "/exact_grid_result.rda"))
plot(x = exact_grid_result$x, y = exact_grid_result$pos, col = "black", cex = 0.5, type = "l",
     xlab = "x", ylab = "density", main = "Posterior Density", lwd = 2)
abline(v = exact_grid_result$x[which.max(exact_grid_result$exact_vals)], col = "green", lty = "dashed")
abline(v = exact_grid_result$x[which.max(exact_grid_result$exact_vals)], col = "blue", lty = "dashed")
abline(v = a, col = "purple", lty = "dashed")
grid()
```



## BOSS Implementation

Now, let's assess the performance of the BOSS algorithm with different choices of $B$, ranging from $10$ to $80$.

```{r message=FALSE, warning=FALSE}
eval_num <- seq(10, 80, by = 5)
# Initialize BOSS with 3 equally spaced design points
initial_design <- 5
```

Running the BOSS algorithm at each $B$:

```{r eval=FALSE}
set.seed(123)
n_grid <- nrow(exact_grid_result); optim.n = 20
objective_func <- eval_once
result_ad <- BOSS(
  func = objective_func,
  update_step = 5, max_iter = (max(eval_num) - initial_design),
  optim.n = optim.n,
  delta = 0.01, noise_var = noise_var,
  lower = lower, upper = upper,
  # Checking KL convergence
  criterion = "KL", KL.grid = 3000, KL_check_warmup = 5, KL_iter_check = 5, KL_eps = 0,
  initial_design = initial_design
)
BO_result_list <- list()
BO_result_original_list <- list()
for (i in 1:length(eval_num)) {
  eval_number <- eval_num[i]
  result_ad_selected <- list(x = result_ad$result$x[1:eval_number, , drop = F],
                             x_original = result_ad$result$x_original[1:eval_number, , drop = F],
                             y = result_ad$result$y[1:eval_number])
  
  # Optimize the hyperparameter
  opt_hyper <- opt_hyperparameters(result_ad_selected, optim.n = optim.n)
  result_ad_selected$length_scale <- opt_hyper$length_scale
  result_ad_selected$signal_var <- opt_hyper$signal_var

  # Compute final surrogate
  data_to_smooth <- result_ad_selected
  data_to_smooth$y <- data_to_smooth$y - mean(data_to_smooth$y)
  BO_result_original_list[[i]] <- data_to_smooth

  ff <- list()
  ff$fn <- function(x) as.numeric(surrogate(x, data_to_smooth = data_to_smooth, choice_cov = square_exp_cov_generator_nd(length_scale = result_ad_selected$length_scale, signal_var = result_ad_selected$signal_var)))
  x_vals <- (seq(from = lower, to = upper, length.out = n_grid) - lower)/(upper - lower)
  fn_vals <- sapply(x_vals, ff$fn)
  obj <- function(x) {exp(ff$fn(x))}
  lognormal_const <- log(integrate(obj, lower = 0, upper = 1, subdivisions = 1000)$value)
  post_x <- data.frame(y = x_vals, pos = exp(fn_vals - lognormal_const))
  BO_result_list[[i]] <- data.frame(x = (lower + x_vals*(upper - lower)), pos = post_x$pos /(upper - lower))
}
save(BO_result_list, file = paste0(output_path, "/BO_result_list.rda"))
save(BO_result_original_list, file = paste0(output_path, "/BO_result_original_list.rda"))
save(result_ad, file = paste0(output_path, "/result_ad.rda"))
```



Take a look at the convergence diagnostic of the BOSS algorithm:

```{r}
load(paste0(output_path, "/result_ad.rda"))
plot(result_ad$KL_result$KL ~ result_ad$KL_result$i, type = "o", xlab = "iteration", ylab = "KL Stats")
```

The KL statistics appears to be stable after $60$ iterations of BO, indicating that the BOSS algorithm likely converges.



Let's compare the results from the BOSS algorithm with the exact grid result:

### {.tabset .tabset-pills}

```{r message=FALSE, warning=FALSE}
load(paste0(output_path, "/BO_result_list.rda"))
load(paste0(output_path, "/BO_result_original_list.rda"))
plot_list <- list()
for (i in 1:length(eval_num)) {
    plot_list[[i]] <- ggplot() +
    geom_line(data = BO_result_list[[i]], aes(x = x, y = pos), color = "red", size = 1) +
    geom_line(data = exact_grid_result, aes(x = x, y = pos), color = "black", size = 1, linetype = "dashed") + 
    ggtitle(paste0("Comparison Posterior Density: B = ", eval_num[i])) +
    xlab("Value") +
    ylab("Density") +
    theme_minimal() +
    theme(text = element_text(size = 10), axis.text = element_text(size = 15)) + # only change the lab and axis text size
    coord_cartesian(ylim = c(0, max(exact_grid_result$pos)))
}
```

#### B = `r eval_num[1]`

```{r}
plot_list[[1]]
```

#### B = `r eval_num[5]`

```{r}
plot_list[[5]]
```

#### B = `r eval_num[9]`

```{r}
plot_list[[9]]
```

#### B = `r eval_num[15]`

```{r}
plot_list[[15]]
```


```{r eval=FALSE, include=FALSE}
# Use tikzDevice to generate the tex file
for (i in 1:length(eval_num)) {
  base_name <- paste0("ComparisonPosteriorDensity_B_", eval_num[i])
  tex_file_name <- paste0("/ComparisonPosteriorDensity_B_", eval_num[i], ".tex")
  pdf_file_name <- paste0("/ComparisonPosteriorDensity_B_", eval_num[i], ".pdf")
  tikzDevice::tikz(file = paste0(".//ComparisonPosteriorDensity_B_", eval_num[i], ".tex"),
                   width = 8, height = 8, standAlone = TRUE)
  ggplot() +
    geom_line(data = BO_result_list[[i]], aes(x = x, y = pos), color = "red", size = 1) +
    geom_line(data = exact_grid_result, aes(x = x, y = pos), color = "black", size = 1, linetype = "dashed") + 
    ggtitle(paste0("Comparison Posterior Density: B = ", eval_num[i])) +
    xlab("Value") +
    ylab("Density") +
    theme_minimal() +
    theme(text = element_text(size = 20), axis.text = element_text(size = 25)) + # only change the lab and axis text size
    lims(y = range(exact_grid_result$pos))
  dev.off()
  
  # Run pdflatex to generate the PDF
  if (file.exists(tex_file_name)) {
    system(sprintf('pdflatex -output-directory=%s "%s"', output_path, tex_file_name))
    
    # Check if the PDF was created
    if (file.exists(pdf_file_name)) {
      # Delete the .tex, .aux, and .log files to clean up
      file.remove(tex_file_name)
      file.remove(paste0(output_path, base_name, ".aux"))
      file.remove(paste0(output_path, base_name, ".log"))
    } else {
      warning("PDF file was not created: ", pdf_file_name)
    }
  } else {
    warning("TeX file was not created: ", tex_file_name)
  }
  ggsave(filename = (paste0(output_path, "/figures/Comparison Posterior Density: B = ", eval_num[i], " .pdf")),
         width = 8, height = 8)
}
```


## Comparison of KL and KS statistics

To assess the accuracy of BOSS, we will compute the KL and KS statistics comparing to the posterior from oracle approach:

```{r message=FALSE, warning=FALSE}
#### Compute the KL distance:
KL_vec <- c()
for (i in 1:length(eval_num)) {
  KL_vec[i] <- Compute_KL(x = exact_grid_result$x, px = exact_grid_result$pos, qx = BO_result_list[[i]]$pos)
}
plot((KL_vec) ~ eval_num, type = "o", ylab = "KL", xlab = "eval number: B", cex.lab = 1, cex.axis = 1)

#### Compute the KS distance:
KS_vec <- c()
for (i in 1:length(eval_num)) {
  KS_vec[i] <- Compute_KS(x = exact_grid_result$x, px = exact_grid_result$pos, qx = BO_result_list[[i]]$pos)
}
plot((KS_vec) ~ eval_num, type = "o", ylab = "KS", xlab = "eval number: B", cex.lab = 1, cex.axis = 1)
```

```{r eval=FALSE, include=FALSE}
tikzDevice::tikz(file = paste0(output_path, "/kl_compare.tex"),
                 width = 8, height = 8, standAlone = TRUE)
plot((KL_vec) ~ eval_num, type = "o", ylab = "KL", xlab = "eval number: B", cex.lab = 2.0, cex.axis = 2.0)
dev.off()
system(paste0('pdflatex -output-directory=', output_path, ' ', output_path, '/kl_compare.tex'))
file.remove(paste0(output_path, "/kl_compare.tex"))
file.remove(paste0(output_path, "/kl_compare.aux"))
file.remove(paste0(output_path, "/kl_compare.log"))

tikzDevice::tikz(file = paste0(output_path, "/ks_compare.tex"),
                 width = 8, height = 8, standAlone = TRUE)
plot((KS_vec) ~ eval_num, type = "o", ylab = "KS", xlab = "eval number: B", cex.lab = 2.0, cex.axis = 2.0)
dev.off()
system(paste0('pdflatex -output-directory=', output_path, ' ', output_path, '/ks_compare.tex'))
file.remove(paste0(output_path, "/ks_compare.tex"))
file.remove(paste0(output_path, "/ks_compare.aux"))
file.remove(paste0(output_path, "/ks_compare.log"))
```


This is the KL and KS distance between BOSS and the exact grid result for this particular replication.
To more robustly assess the performance, let's consider the KL and KS distance over $10$ independent replications.


```{r}
simulate_once <- function(seed){
  set.seed(seed)
  n <- 100; x <- runif(n = n, min = 0, max = 10)
  true_func <- function(x, true_alpha = 1.5) {
    1 +
      0.5 * cos((2 * pi * x) / true_alpha) - 1.3 * sin((2 * pi * x) / true_alpha) +
      1.1 * cos((4 * pi * x) / true_alpha) + 0.3 * sin((4 * pi * x) / true_alpha)
  }
  log_mu <- true_func(x) + rnorm(n, sd = 2)
  y <- rpois(n = n, lambda = exp(log_mu))
  data <- data.frame(
    y = y,
    x = x,
    indx = 1:n,
    log_mu = log_mu
  )
  
  # Define the objective function
  eval_once <- function(alpha){
  a_fit <- (2*pi)/alpha
  x <- data$x
  data$cosx <- cos(a_fit * x)
  data$sinx <- sin(a_fit * x)
  data$cos2x <- cos(2*a_fit * x)
  data$sin2x <- sin(2*a_fit * x)
  mod <- model_fit(formula = y ~ cosx + sinx + cos2x + sin2x + f(x = indx, model = "IID", 
                                                                 sd.prior = list(param = 1)),
                   data = data, method = "aghq", family = "Poisson", aghq_k = 4
  )
  (mod$mod$normalized_posterior$lognormconst) + log_prior(alpha)
}

  
  #################################
  #################################
  #########  Fitting Grid: ########
  #################################
  #################################
  #################################
  exact_vals <- c()
  total <- length(x_vals)
  pb <- txtProgressBar(min = 0, max = total, style = 3)
  for (i in 1:total) {
    xi <- x_vals[i]
    exact_vals <- c(exact_vals, eval_once(xi))
    setTxtProgressBar(pb, i)
  }
  close(pb)
  exact_grid_result <- data.frame(x = x_vals, exact_vals = exact_vals)
  exact_grid_result$exact_vals <- exact_grid_result$exact_vals - max(exact_grid_result$exact_vals)
  exact_grid_result$fx <- exp(exact_grid_result$exact_vals)
  
  # Calculate the differences between adjacent x values
  dx <- diff(exact_grid_result$x)
  # Compute the trapezoidal areas and sum them up
  integral_approx <- sum(0.5 * (exact_grid_result$fx[-1] + exact_grid_result$fx[-length(exact_grid_result$fx)]) * dx)
  exact_grid_result$pos <- exact_grid_result$fx / integral_approx
  
  #################################
  #################################
  #########  Fitting BOSS: ########
  #################################
  #################################
  #################################
n_grid <- nrow(exact_grid_result); optim.n = 20
objective_func <- eval_once
result_ad <- BOSS(
  func = objective_func,
  update_step = 5, max_iter = (max(eval_num) - initial_design),
  optim.n = optim.n,
  delta = 0.01, noise_var = noise_var,
  lower = lower, upper = upper,
  # Checking KL convergence
  criterion = "KL", KL.grid = 3000, KL_check_warmup = 5, KL_iter_check = 5, KL_eps = 0,
  initial_design = initial_design
)
BO_result_list <- list()
BO_result_original_list <- list()
for (i in 1:length(eval_num)) {
  eval_number <- eval_num[i]
  result_ad_selected <- list(x = result_ad$result$x[1:eval_number, , drop = F],
                             x_original = result_ad$result$x_original[1:eval_number, , drop = F],
                             y = result_ad$result$y[1:eval_number])
  
  # Optimize the hyperparameter
  opt_hyper <- opt_hyperparameters(result_ad_selected, optim.n = optim.n)
  result_ad_selected$length_scale <- opt_hyper$length_scale
  result_ad_selected$signal_var <- opt_hyper$signal_var

  # Compute final surrogate
  data_to_smooth <- result_ad_selected
  data_to_smooth$y <- data_to_smooth$y - mean(data_to_smooth$y)
  BO_result_original_list[[i]] <- data_to_smooth

  ff <- list()
  ff$fn <- function(x) as.numeric(surrogate(x, data_to_smooth = data_to_smooth, choice_cov = square_exp_cov_generator_nd(length_scale = result_ad_selected$length_scale, signal_var = result_ad_selected$signal_var)))
  x_vals <- (seq(from = lower, to = upper, length.out = n_grid) - lower)/(upper - lower)
  fn_vals <- sapply(x_vals, ff$fn)
  obj <- function(x) {exp(ff$fn(x))}
  lognormal_const <- log(integrate(obj, lower = 0, upper = 1, subdivisions = 1000)$value)
  post_x <- data.frame(y = x_vals, pos = exp(fn_vals - lognormal_const))
  BO_result_list[[i]] <- data.frame(x = (lower + x_vals*(upper - lower)), pos = post_x$pos /(upper - lower))
}
  
  #################################
  #################################
  ######### Compute KS/KL: ########
  #################################
  #################################
  #################################
  #### Compute the KL distance:
  KL_vec <- c()
  for (i in 1:length(eval_num)) {
    KL_vec[i] <- Compute_KL(x = exact_grid_result$x,
                            px = exact_grid_result$pos,
                            qx = BO_result_list[[i]]$pos)
  }
  
  #### Compute the KS distance:
  KS_vec <- c()
  for (i in 1:length(eval_num)) {
    KS_vec[i] <- Compute_KS(x = exact_grid_result$x,
                            px = exact_grid_result$pos,
                            qx = BO_result_list[[i]]$pos)
  }
  
  return(data.frame(eval_num = eval_num, KL = KL_vec, KS = KS_vec))
}
```


```{r eval=FALSE}
all_result <- data.frame(eval_num = eval_num,
                         KL = KL_vec,
                         KS = KS_vec)
seed_vec <- 1:10
for (i in 1:length(seed_vec)) {
  seed <- seed_vec[i]
  result <- simulate_once(seed = seed)
  all_result <- rbind(all_result, result)
}
save(all_result, file = paste0(output_path, "/all_result.rda"))
```


Plot the results across $10$ independent replications:

```{r}
load(paste0(output_path, "/all_result.rda"))

median_result <- all_result %>% group_by(eval_num) %>%
  summarise(KL = median(KL), KS = median(KS))

lower_result <- all_result %>% group_by(eval_num) %>%
  summarise(KL = quantile(KL, 0.1), KS = quantile(KS, 0.1))

upper_result <- all_result %>% group_by(eval_num) %>%
  summarise(KL = quantile(KL, 0.9), KS = quantile(KS, 0.9))

plot(median_result$eval_num, median_result$KL, type = "o", 
     ylab = "KL", xlab = "eval number: B",
     cex.lab = 1.0, cex.axis = 1.0)
polygon(c(median_result$eval_num, rev(median_result$eval_num)), 
        c(lower_result$KL, rev(upper_result$KL)), 
        col = rgb(0.2, 0.2, 0.2, 0.2), border = NA)

plot(median_result$eval_num, median_result$KS, type = "o",
     ylab = "KS", xlab = "eval number: B", 
     cex.lab = 1.0, cex.axis = 1.0)
polygon(c(median_result$eval_num, rev(median_result$eval_num)), 
        c(lower_result$KS, rev(upper_result$KS)), 
        col = rgb(0.2, 0.2, 0.2, 0.2), border = NA)
```


